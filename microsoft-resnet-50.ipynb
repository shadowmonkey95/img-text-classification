{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from transformers import AutoImageProcessor, ResNetForImageClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrademarkDataset(Dataset):\n",
    "    def __init__(self, df, target_column, img_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_column = target_column\n",
    "        \n",
    "        # Encode target labels\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.labels = self.label_encoder.fit_transform(df[target_column].str.split(',').str[0])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_path = os.path.join(self.img_dir, self.df.iloc[idx]['image_name'])\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "                \n",
    "            label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {self.df.iloc[idx]['image_name']}: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_image_existence(df, img_dir):\n",
    "    \"\"\"\n",
    "    Check and filter the DataFrame to keep only rows where images exist and can be opened.\n",
    "    \"\"\"\n",
    "    missing_images = []\n",
    "    corrupted_images = []\n",
    "    valid_rows = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Checking images\"):\n",
    "        img_path = os.path.join(img_dir, row['image_name'])\n",
    "        try:\n",
    "            # Try to open the image to check if it's valid\n",
    "            with Image.open(img_path) as img:\n",
    "                img.verify()  # Verify it's actually an image\n",
    "            valid_rows.append(True)\n",
    "        except (FileNotFoundError, Image.UnidentifiedImageError, IOError):\n",
    "            valid_rows.append(False)\n",
    "            if not os.path.exists(img_path):\n",
    "                missing_images.append(row['image_name'])\n",
    "            else:\n",
    "                corrupted_images.append(row['image_name'])\n",
    "    \n",
    "    valid_df = df[valid_rows].copy()\n",
    "    \n",
    "    print(f\"\\nTotal images in CSV: {len(df)}\")\n",
    "    print(f\"Missing images: {len(missing_images)}\")\n",
    "    print(f\"Corrupted images: {len(corrupted_images)}\")\n",
    "    print(f\"Valid images: {len(valid_df)}\")\n",
    "    \n",
    "    return valid_df, missing_images, corrupted_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_trademark_classifier(df, target_column, img_dir, num_epochs=10, batch_size=32):\n",
    "    train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # Define transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = TrademarkDataset(train_df, target_column, img_dir, transform)\n",
    "    val_dataset = TrademarkDataset(val_df, target_column, img_dir, transform)\n",
    "    test_dataset = TrademarkDataset(test_df, target_column, img_dir, transform)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Initialize model\n",
    "    num_classes = len(train_dataset.label_encoder.classes_)\n",
    "    model = ResNetForImageClassification.from_pretrained(\n",
    "        \"microsoft/resnet-50\",\n",
    "        num_labels=num_classes,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "    \n",
    "    # Move model to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_acc = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images).logits\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Print epoch statistics\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'Train Loss: {train_loss/len(train_loader):.4f}, '\n",
    "              f'Train Acc: {100.*train_correct/train_total:.2f}%')\n",
    "        print(f'Val Loss: {val_loss/len(val_loader):.4f}, '\n",
    "              f'Val Acc: {100.*val_correct/val_total:.2f}%')\n",
    "        \n",
    "        # Save best model\n",
    "        val_acc = 100.*val_correct/val_total\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), f'best_model_{target_column}.pth')\n",
    "    \n",
    "    # Test phase\n",
    "    model.load_state_dict(torch.load(f'best_model_{target_column}.pth'))\n",
    "    model.eval()\n",
    "    \n",
    "    test_predictions = []\n",
    "    test_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images).logits\n",
    "            _, predicted = outputs.max(1)\n",
    "            test_predictions.extend(predicted.cpu().numpy())\n",
    "            test_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Convert numeric predictions back to original labels\n",
    "    pred_labels = train_dataset.label_encoder.inverse_transform(test_predictions)\n",
    "    true_labels = train_dataset.label_encoder.inverse_transform(test_labels)\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, pred_labels))\n",
    "    \n",
    "    return model, train_dataset.label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Starting trademark classification pipeline...\")\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv('./data/csv/pretrain_fill.csv')\n",
    "    img_dir = './data/img/'  # Updated path to match your structure\n",
    "    \n",
    "    # Validate images first\n",
    "    print(\"\\nValidating image files...\")\n",
    "    valid_df, missing_images, corrupted_images = validate_image_existence(df, img_dir)\n",
    "    \n",
    "    # Save validation results\n",
    "    if len(missing_images) > 0 or len(corrupted_images) > 0:\n",
    "        print(\"\\nWarning: Some images are missing or corrupted!\")\n",
    "        \n",
    "        # Save missing images list\n",
    "        with open('missing_images.txt', 'w') as f:\n",
    "            f.write(\"Missing images:\\n\")\n",
    "            for img in missing_images:\n",
    "                f.write(f\"{img}\\n\")\n",
    "            f.write(\"\\nCorrupted images:\\n\")\n",
    "            for img in corrupted_images:\n",
    "                f.write(f\"{img}\\n\")\n",
    "        print(\"Image issues list saved to 'missing_images.txt'\")\n",
    "        \n",
    "        # Save valid dataset\n",
    "        valid_df.to_csv('pretrain_fill_valid.csv', index=False)\n",
    "        print(\"Valid dataset saved to 'pretrain_fill_valid.csv'\")\n",
    "    \n",
    "    # Check if we have enough data to proceed\n",
    "    if len(valid_df) < 10:\n",
    "        print(\"Error: Not enough valid images to train. Please check your dataset.\")\n",
    "        return\n",
    "    \n",
    "    # Train models for different hierarchical levels\n",
    "    # hierarchical_levels = ['target', 'target_h1', 'target_h2', 'target_h3']\n",
    "    hierarchical_levels = ['target_h1']\n",
    "    \n",
    "    for level in hierarchical_levels:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training model for {level}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        try:\n",
    "            model, label_encoder = train_trademark_classifier(valid_df, level, img_dir)\n",
    "            \n",
    "            # Save label encoder for later use\n",
    "            joblib.dump(label_encoder, f'label_encoder_{level}.pkl')\n",
    "            print(f\"\\nModel and label encoder for {level} saved successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError training model for {level}: {str(e)}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trademark classification pipeline...\n",
      "\n",
      "Validating image files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking images: 100%|██████████| 158511/158511 [01:38<00:00, 1616.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total images in CSV: 158511\n",
      "Missing images: 55178\n",
      "Corrupted images: 12\n",
      "Valid images: 103321\n",
      "\n",
      "Warning: Some images are missing or corrupted!\n",
      "Image issues list saved to 'missing_images.txt'\n",
      "Valid dataset saved to 'pretrain_fill_valid.csv'\n",
      "\n",
      "==================================================\n",
      "Training model for target_h1\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n",
      "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([30]) in the model instantiated\n",
      "- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([30, 2048]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1/10: 100%|██████████| 2261/2261 [17:40<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "Train Loss: 2.2277, Train Acc: 39.41%\n",
      "Val Loss: 1.9652, Val Acc: 44.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 2261/2261 [17:57<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:\n",
      "Train Loss: 1.8848, Train Acc: 46.59%\n",
      "Val Loss: 1.8066, Val Acc: 48.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 2261/2261 [17:33<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:\n",
      "Train Loss: 1.7682, Train Acc: 50.17%\n",
      "Val Loss: 1.7288, Val Acc: 51.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 2261/2261 [17:35<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:\n",
      "Train Loss: 1.6868, Train Acc: 52.46%\n",
      "Val Loss: 1.6712, Val Acc: 53.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 2261/2261 [17:20<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:\n",
      "Train Loss: 1.6184, Train Acc: 54.38%\n",
      "Val Loss: 1.6338, Val Acc: 53.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 2261/2261 [17:12<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:\n",
      "Train Loss: 1.5610, Train Acc: 55.76%\n",
      "Val Loss: 1.6043, Val Acc: 54.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 2261/2261 [17:18<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:\n",
      "Train Loss: 1.5073, Train Acc: 57.36%\n",
      "Val Loss: 1.5898, Val Acc: 55.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 2261/2261 [17:38<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:\n",
      "Train Loss: 1.4574, Train Acc: 58.68%\n",
      "Val Loss: 1.5653, Val Acc: 56.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 2261/2261 [17:16<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:\n",
      "Train Loss: 1.4084, Train Acc: 60.03%\n",
      "Val Loss: 1.5649, Val Acc: 56.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 2261/2261 [17:19<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:\n",
      "Train Loss: 1.3585, Train Acc: 61.24%\n",
      "Val Loss: 1.5587, Val Acc: 56.76%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          01       0.43      0.45      0.44      2106\n",
      "          02       0.50      0.42      0.46      1546\n",
      "          03       0.50      0.53      0.52      1345\n",
      "          04       0.00      0.00      0.00       113\n",
      "          05       0.50      0.50      0.50      1044\n",
      "          06       0.00      0.00      0.00       123\n",
      "          07       0.42      0.22      0.29       268\n",
      "          08       0.00      0.00      0.00        71\n",
      "          09       0.43      0.13      0.20       165\n",
      "          10       0.00      0.00      0.00        38\n",
      "          11       0.00      0.00      0.00        78\n",
      "          12       0.00      0.00      0.00        16\n",
      "          13       0.00      0.00      0.00        35\n",
      "          14       0.00      0.00      0.00       172\n",
      "          15       0.00      0.00      0.00       102\n",
      "          16       0.00      0.00      0.00        87\n",
      "          17       1.00      0.01      0.02       123\n",
      "          18       0.40      0.01      0.02       177\n",
      "          19       0.46      0.52      0.49       176\n",
      "          20       0.00      0.00      0.00       115\n",
      "          21       0.00      0.00      0.00       116\n",
      "          22       0.00      0.00      0.00        21\n",
      "          23       0.00      0.00      0.00        31\n",
      "          24       0.33      0.09      0.14       854\n",
      "          25       0.50      0.04      0.08        89\n",
      "          26       0.63      0.90      0.74      5911\n",
      "          27       0.00      0.00      0.00        15\n",
      "          28       0.86      0.70      0.77       536\n",
      "          29       0.00      0.00      0.00        21\n",
      "          []       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.57     15499\n",
      "   macro avg       0.23      0.15      0.16     15499\n",
      "weighted avg       0.51      0.57      0.52     15499\n",
      "\n",
      "\n",
      "Model and label encoder for target_h1 saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pham_dinh_vu/code/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/pham_dinh_vu/code/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/pham_dinh_vu/code/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
