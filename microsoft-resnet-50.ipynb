{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vuphamas/code/img-text-classification/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from transformers import AutoImageProcessor, ResNetForImageClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrademarkDataset(Dataset):\n",
    "    def __init__(self, df, target_column, img_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_column = target_column\n",
    "        \n",
    "        # Encode target labels\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.labels = self.label_encoder.fit_transform(df[target_column].str.split(',').str[0])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_path = os.path.join(self.img_dir, self.df.iloc[idx]['image_name'])\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "                \n",
    "            label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {self.df.iloc[idx]['image_name']}: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_image_existence(df, img_dir):\n",
    "    \"\"\"\n",
    "    Check and filter the DataFrame to keep only rows where images exist and can be opened.\n",
    "    \"\"\"\n",
    "    missing_images = []\n",
    "    corrupted_images = []\n",
    "    valid_rows = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Checking images\"):\n",
    "        img_path = os.path.join(img_dir, row['image_name'])\n",
    "        try:\n",
    "            # Try to open the image to check if it's valid\n",
    "            with Image.open(img_path) as img:\n",
    "                img.verify()  # Verify it's actually an image\n",
    "            valid_rows.append(True)\n",
    "        except (FileNotFoundError, Image.UnidentifiedImageError, IOError):\n",
    "            valid_rows.append(False)\n",
    "            if not os.path.exists(img_path):\n",
    "                missing_images.append(row['image_name'])\n",
    "            else:\n",
    "                corrupted_images.append(row['image_name'])\n",
    "    \n",
    "    valid_df = df[valid_rows].copy()\n",
    "    \n",
    "    print(f\"\\nTotal images in CSV: {len(df)}\")\n",
    "    print(f\"Missing images: {len(missing_images)}\")\n",
    "    print(f\"Corrupted images: {len(corrupted_images)}\")\n",
    "    print(f\"Valid images: {len(valid_df)}\")\n",
    "    \n",
    "    return valid_df, missing_images, corrupted_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_trademark_classifier(df, target_column, img_dir, num_epochs=10, batch_size=32):\n",
    "    train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # Define transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = TrademarkDataset(train_df, target_column, img_dir, transform)\n",
    "    val_dataset = TrademarkDataset(val_df, target_column, img_dir, transform)\n",
    "    test_dataset = TrademarkDataset(test_df, target_column, img_dir, transform)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Initialize model\n",
    "    num_classes = len(train_dataset.label_encoder.classes_)\n",
    "    model = ResNetForImageClassification.from_pretrained(\n",
    "        \"microsoft/resnet-50\",\n",
    "        num_labels=num_classes,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "    \n",
    "    # Move model to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_acc = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images).logits\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Print epoch statistics\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'Train Loss: {train_loss/len(train_loader):.4f}, '\n",
    "              f'Train Acc: {100.*train_correct/train_total:.2f}%')\n",
    "        print(f'Val Loss: {val_loss/len(val_loader):.4f}, '\n",
    "              f'Val Acc: {100.*val_correct/val_total:.2f}%')\n",
    "        \n",
    "        # Save best model\n",
    "        val_acc = 100.*val_correct/val_total\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), f'best_model_{target_column}.pth')\n",
    "    \n",
    "    # Test phase\n",
    "    model.load_state_dict(torch.load(f'best_model_{target_column}.pth'))\n",
    "    model.eval()\n",
    "    \n",
    "    test_predictions = []\n",
    "    test_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images).logits\n",
    "            _, predicted = outputs.max(1)\n",
    "            test_predictions.extend(predicted.cpu().numpy())\n",
    "            test_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Convert numeric predictions back to original labels\n",
    "    pred_labels = train_dataset.label_encoder.inverse_transform(test_predictions)\n",
    "    true_labels = train_dataset.label_encoder.inverse_transform(test_labels)\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, pred_labels))\n",
    "    \n",
    "    return model, train_dataset.label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Starting trademark classification pipeline...\")\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv('./data/csv/pretrain_fill.csv')\n",
    "    img_dir = './data/img/'  # Updated path to match your structure\n",
    "    \n",
    "    # Validate images first\n",
    "    print(\"\\nValidating image files...\")\n",
    "    valid_df, missing_images, corrupted_images = validate_image_existence(df, img_dir)\n",
    "    \n",
    "    # Save validation results\n",
    "    if len(missing_images) > 0 or len(corrupted_images) > 0:\n",
    "        print(\"\\nWarning: Some images are missing or corrupted!\")\n",
    "        \n",
    "        # Save missing images list\n",
    "        with open('missing_images.txt', 'w') as f:\n",
    "            f.write(\"Missing images:\\n\")\n",
    "            for img in missing_images:\n",
    "                f.write(f\"{img}\\n\")\n",
    "            f.write(\"\\nCorrupted images:\\n\")\n",
    "            for img in corrupted_images:\n",
    "                f.write(f\"{img}\\n\")\n",
    "        print(\"Image issues list saved to 'missing_images.txt'\")\n",
    "        \n",
    "        # Save valid dataset\n",
    "        valid_df.to_csv('pretrain_fill_valid.csv', index=False)\n",
    "        print(\"Valid dataset saved to 'pretrain_fill_valid.csv'\")\n",
    "    \n",
    "    # Check if we have enough data to proceed\n",
    "    if len(valid_df) < 10:\n",
    "        print(\"Error: Not enough valid images to train. Please check your dataset.\")\n",
    "        return\n",
    "    \n",
    "    # Train models for different hierarchical levels\n",
    "    # hierarchical_levels = ['target', 'target_h1', 'target_h2', 'target_h3']\n",
    "    hierarchical_levels = ['target_h1']\n",
    "    \n",
    "    for level in hierarchical_levels:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training model for {level}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        try:\n",
    "            model, label_encoder = train_trademark_classifier(valid_df, level, img_dir)\n",
    "            \n",
    "            # Save label encoder for later use\n",
    "            import joblib\n",
    "            joblib.dump(label_encoder, f'label_encoder_{level}.pkl')\n",
    "            print(f\"\\nModel and label encoder for {level} saved successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError training model for {level}: {str(e)}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trademark classification pipeline...\n",
      "\n",
      "Validating image files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking images: 100%|██████████| 158511/158511 [03:26<00:00, 766.65it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total images in CSV: 158511\n",
      "Missing images: 55178\n",
      "Corrupted images: 12\n",
      "Valid images: 103321\n",
      "\n",
      "Warning: Some images are missing or corrupted!\n",
      "Image issues list saved to 'missing_images.txt'\n",
      "Valid dataset saved to 'pretrain_fill_valid.csv'\n",
      "\n",
      "==================================================\n",
      "Training model for target_h1\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n",
      "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([30]) in the model instantiated\n",
      "- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([30, 2048]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1/10:  24%|██▍       | 541/2261 [10:09:18<32:17:10, 67.58s/it]    \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
